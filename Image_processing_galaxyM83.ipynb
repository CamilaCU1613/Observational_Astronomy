{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b38cc4-88b1-414e-bad5-c8488c718b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import CCDData\n",
    "import ccdproc\n",
    "from astropy import units as u\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from scipy.ndimage import shift\n",
    "from collections import defaultdict\n",
    "\n",
    "# Base route\n",
    "base_path = \"./\"\n",
    "\n",
    "# Function to get valid FITS files\n",
    "def get_fits_files(folder_path, prefix):\n",
    "    files = []\n",
    "    for f in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, f)\n",
    "        if f.startswith(prefix) and os.path.isfile(full_path) and f.lower().endswith(('.fits', '.fit')):\n",
    "            files.append(full_path)\n",
    "    return sorted(files)\n",
    "\n",
    "# File paths - now checking that they are valid files\n",
    "bias_files = get_fits_files(base_path, \"bias\")\n",
    "dark_files = get_fits_files(base_path, \"dark\")\n",
    "flat_files = get_fits_files(base_path, \"flat\")\n",
    "light_files = get_fits_files(base_path, \"M83\")\n",
    "\n",
    "# Verify that there are files to process\n",
    "if not bias_files:\n",
    "    raise ValueError(\"No valid bias files were found in the specified path\")\n",
    "if not dark_files:\n",
    "    print(\"Warning: No valid dark files found\")\n",
    "if not flat_files:\n",
    "    raise ValueError(\"No valid flat files were found\")\n",
    "if not light_files:\n",
    "    raise ValueError(\"No valid light files were found\")\n",
    "\n",
    "# Create output folders\n",
    "aligned_dir = os.path.join(base_path, \"Aligned\")\n",
    "processed_dir = os.path.join(base_path, \"Processed\")\n",
    "summed_dir = os.path.join(base_path, \"Summed\")\n",
    "\n",
    "os.makedirs(aligned_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(summed_dir, exist_ok=True)\n",
    "\n",
    "def combine_images(file_list):\n",
    "    data_stack = []\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            data = fits.getdata(f).astype(float)\n",
    "            data_stack.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {f}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not data_stack:\n",
    "        raise ValueError(\"Could not load images to combine\")\n",
    "    \n",
    "    return np.median(data_stack, axis=0)\n",
    "\n",
    "# Process master bias\n",
    "try:\n",
    "    master_bias = combine_images(bias_files)\n",
    "    fits.writeto(os.path.join(base_path, \"master_bias.fits\"), master_bias, overwrite=True)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error al crear master bias: {str(e)}\")\n",
    "\n",
    "# Process master dark (if there are files)\n",
    "master_dark = np.zeros_like(master_bias) # Default value if there are no darks\n",
    "if dark_files:\n",
    "    try:\n",
    "        master_dark = combine_images(dark_files)\n",
    "        fits.writeto(os.path.join(base_path, \"master_dark.fits\"), master_dark, overwrite=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning Error creating master dark: {str(e)}. Using array of zeros.\")\n",
    "\n",
    "def extract_filter(filename):\n",
    "    filename_lower = filename.lower()\n",
    "    if \"_g_\" in filename_lower:\n",
    "        return \"g\"\n",
    "    elif \"_r_\" in filename_lower:\n",
    "        return \"r\"\n",
    "    elif \"_i_\" in filename_lower:\n",
    "        return \"i\"\n",
    "    return None\n",
    "\n",
    "master_flats = {}\n",
    "\n",
    "for filt in [\"g\", \"r\", \"i\"]:\n",
    "    flat_filt_files = [f for f in flat_files if f\"_{filt}_\" in f.lower()]\n",
    "    if not flat_filt_files:\n",
    "        print(f\"Warning: No flats found for the filter {filt}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        flat_stack = [(fits.getdata(f).astype(float) - master_bias) for f in flat_filt_files]\n",
    "        median_flat = np.median(flat_stack, axis=0)\n",
    "        norm_flat = median_flat / np.mean(median_flat)\n",
    "        master_flats[filt] = norm_flat\n",
    "        fits.writeto(os.path.join(base_path, f\"master_flat_{filt}.fits\"), norm_flat, overwrite=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing flats for filter {filt}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "def reduce_light(path, filt):\n",
    "    try:\n",
    "        data = fits.getdata(path).astype(float)\n",
    "        if filt not in master_flats:\n",
    "            raise ValueError(f\"There is no master flat for the filter {filt}\")\n",
    "        reduced = (data - master_dark) / master_flats[filt]\n",
    "        return reduced\n",
    "    except Exception as e:\n",
    "        print(f\"Error reducing {path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def enhanced_align_images(image_list, reference_image=None, upsample_factor=10):\n",
    "    if not image_list:\n",
    "        return []\n",
    "    \n",
    "    aligned = []\n",
    "    \n",
    "    if reference_image is None:\n",
    "        ref_image = image_list[0]\n",
    "        aligned.append(ref_image)\n",
    "        images_to_align = image_list[1:]\n",
    "    else:\n",
    "        ref_image = reference_image\n",
    "        images_to_align = image_list\n",
    "    \n",
    "    #Preprocessing: crop edges to avoid artifacts\n",
    "    crop_pixels = 50\n",
    "    h, w = ref_image.shape\n",
    "    ref_cropped = ref_image[crop_pixels:h-crop_pixels, crop_pixels:w-crop_pixels]\n",
    "    \n",
    "    for img in images_to_align:\n",
    "        try:\n",
    "            img_cropped = img[crop_pixels:h-crop_pixels, crop_pixels:w-crop_pixels]\n",
    "            \n",
    "            # Use phase_cross_correlation more accurately\n",
    "            shift_val, error, diffphase = phase_cross_correlation(\n",
    "                ref_cropped, \n",
    "                img_cropped, \n",
    "                upsample_factor=upsample_factor,\n",
    "                normalization=None\n",
    "            )\n",
    "            \n",
    "           # Apply the shift to the entire image\n",
    "            shifted = shift(img, shift_val, mode='reflect')\n",
    "            aligned.append(shifted)\n",
    "            \n",
    "            print(f\"Calculated displacement: {shift_val} (error: {error:.4f}, diffphase: {diffphase:.4f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error aligning image: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return aligned if reference_image is None else aligned\n",
    "\n",
    "light_by_filter = defaultdict(list)\n",
    "for f in light_files:\n",
    "    filt = extract_filter(f)\n",
    "    if filt:\n",
    "        light_by_filter[filt].append(f)\n",
    "\n",
    "# Process filters that align well first (r and i)\n",
    "reference_image = None\n",
    "for filt in [\"r\", \"i\"]:\n",
    "    if filt in light_by_filter and light_by_filter[filt]:\n",
    "        print(f\"\\nProcessing filter {filt} with {len(light_by_filter[filt])} imagen...\")\n",
    "        \n",
    "        reduced_imgs = []\n",
    "        for f in light_by_filter[filt]:\n",
    "            reduced = reduce_light(f, filt)\n",
    "            if reduced is not None:\n",
    "                reduced_imgs.append(reduced)\n",
    "        \n",
    "        if reduced_imgs:\n",
    "            aligned_imgs = enhanced_align_images(reduced_imgs, upsample_factor=20)\n",
    "            \n",
    "            for i, img in enumerate(aligned_imgs):\n",
    "                output_path = os.path.join(aligned_dir, f\"aligned_{filt}_{i+1:03d}.fits\")\n",
    "                fits.writeto(output_path, img, overwrite=True)\n",
    "                print(f\"Save: {output_path}\")\n",
    "            \n",
    "            # Save the first aligned image as a reference for the g filter\n",
    "            if reference_image is None and aligned_imgs:\n",
    "                reference_image = aligned_imgs[0]\n",
    "\n",
    "# Process the g filter using the reference of r or i\n",
    "if \"g\" in light_by_filter and light_by_filter[\"g\"]:\n",
    "    print(\"\\nProcessing g filter using r/i reference...\")\n",
    "    \n",
    "    reduced_imgs = []\n",
    "    for f in light_by_filter[\"g\"]:\n",
    "        reduced = reduce_light(f, \"g\")\n",
    "        if reduced is not None:\n",
    "            reduced_imgs.append(reduced)\n",
    "    \n",
    "    if reduced_imgs:\n",
    "        if reference_image is not None:\n",
    "            print(\"Aligning with reference image\")\n",
    "            aligned_imgs = enhanced_align_images(reduced_imgs, reference_image=reference_image, upsample_factor=20)\n",
    "        else:\n",
    "            print(\"No reference image available, aligning g internally\")\n",
    "            aligned_imgs = enhanced_align_images(reduced_imgs, upsample_factor=20)\n",
    "        \n",
    "        for i, img in enumerate(aligned_imgs):\n",
    "            output_path = os.path.join(aligned_dir, f\"aligned_g_{i+1:03d}.fits\")\n",
    "            fits.writeto(output_path, img, overwrite=True)\n",
    "            print(f\"Guardado: {output_path}\")\n",
    "\n",
    "# Combine aligned images\n",
    "for filt in [\"g\", \"r\", \"i\"]:\n",
    "    if filt in light_by_filter:\n",
    "        aligned_files = []\n",
    "        for f in os.listdir(aligned_dir):\n",
    "            if f.startswith(f\"aligned_{filt}\") and f.lower().endswith(('.fits', '.fit')):\n",
    "                aligned_files.append(os.path.join(aligned_dir, f))\n",
    "        \n",
    "        aligned_files = sorted(aligned_files)\n",
    "        if aligned_files:\n",
    "            stack = []\n",
    "            for f in aligned_files:\n",
    "                try:\n",
    "                    data = fits.getdata(f).astype(float)\n",
    "                    stack.append(data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error {f}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if stack:\n",
    "                summed = np.median(stack, axis=0)\n",
    "                summed_path = os.path.join(summed_dir, f\"stacked_{filt}.fits\")\n",
    "                fits.writeto(summed_path, summed, overwrite=True)\n",
    "                print(f\"Save: {summed_path}\")\n",
    "            else:\n",
    "                print(f\"There are no valid images to combine in the filter. {filt}\")\n",
    "        else:\n",
    "            print(f\"No aligned files found for the filter {filt}\")\n",
    "\n",
    "print(\"\\nProcess completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a83462-cf74-4fc2-a4de-2c7c860e769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from image_registration import chi2_shift\n",
    "from image_registration.fft_tools import shift as img_shift\n",
    "\n",
    "# Base path\n",
    "base_path = \"./\"\n",
    "summed_dir = os.path.join(base_path, \"Summed\")\n",
    "aligned_summed_dir = os.path.join(base_path, \"Aligned_Summed\")\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(aligned_summed_dir, exist_ok=True)\n",
    "\n",
    "# Load the stacked images\n",
    "def load_stacked_images():\n",
    "    stacked_files = {\n",
    "        'g': os.path.join(summed_dir, \"stacked_g.fits\"),\n",
    "        'r': os.path.join(summed_dir, \"stacked_r.fits\"),\n",
    "        'i': os.path.join(summed_dir, \"stacked_i.fits\")\n",
    "    }\n",
    "    \n",
    "    images = {}\n",
    "    for filt, path in stacked_files.items():\n",
    "        if os.path.exists(path):\n",
    "            images[filt] = fits.getdata(path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Align images using chi2_shift\n",
    "def align_with_chi2(images):\n",
    "    # Choose the image with best quality as reference (typically r)\n",
    "    reference = images['r']\n",
    "    aligned = {'r': reference}\n",
    "    \n",
    "    # Parameters for chi2_shift\n",
    "    noise_level = np.std(reference)  # Estimate of noise level\n",
    "    upsample_factor = 'auto'  # You can adjust this if needed\n",
    "    \n",
    "    print(\"\\nStarting alignment with chi2_shift...\")\n",
    "    \n",
    "    # Align g with respect to r\n",
    "    print(\"Aligning filter g...\")\n",
    "    xoff_g, yoff_g, exoff_g, eyoff_g = chi2_shift(\n",
    "        reference, images['g'], noise_level,\n",
    "        return_error=True, upsample_factor=upsample_factor\n",
    "    )\n",
    "    aligned['g'] = img_shift.shiftnd(images['g'], (-yoff_g, -xoff_g))\n",
    "    print(f\"Displacement g: x={xoff_g:.2f} ± {exoff_g:.2f}, y={yoff_g:.2f} ± {eyoff_g:.2f}\")\n",
    "    \n",
    "    # Align i with respect to r\n",
    "    print(\"Aligning filter i...\")\n",
    "    xoff_i, yoff_i, exoff_i, eyoff_i = chi2_shift(\n",
    "        reference, images['i'], noise_level,\n",
    "        return_error=True, upsample_factor=upsample_factor\n",
    "    )\n",
    "    aligned['i'] = img_shift.shiftnd(images['i'], (-yoff_i, -xoff_i))\n",
    "    print(f\"Displacement i: x={xoff_i:.2f} ± {exoff_i:.2f}, y={yoff_i:.2f} ± {eyoff_i:.2f}\")\n",
    "    \n",
    "    return aligned\n",
    "\n",
    "# Save aligned images\n",
    "def save_aligned_images(aligned_images):\n",
    "    for filt, img in aligned_images.items():\n",
    "        output_path = os.path.join(aligned_summed_dir, f\"aligned_stacked_{filt}.fits\")\n",
    "        fits.writeto(output_path, img, overwrite=True)\n",
    "        print(f\"Aligned image {filt} saved to: {output_path}\")\n",
    "\n",
    "# Main process\n",
    "def main():\n",
    "    try:\n",
    "        # Load images\n",
    "        print(\"Loading stacked images...\")\n",
    "        images = load_stacked_images()\n",
    "        \n",
    "        # Align images\n",
    "        aligned_images = align_with_chi2(images)\n",
    "        \n",
    "        # Save results\n",
    "        save_aligned_images(aligned_images)\n",
    "        \n",
    "        print(\"\\nAlignment completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during the process: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae2176-055d-4733-9913-562a0ead61bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
